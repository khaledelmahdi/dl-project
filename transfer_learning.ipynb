{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install -q opencv-python\n",
    "!pip install -q pydot\n",
    "!pip install -q graphviz\n",
    "!pip install -q torchview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload kaggle.json file\n",
    "# from google.colab import files\n",
    "# files.upload()\n",
    "\n",
    "# Remove file if exist\n",
    "# !rm ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Create a kaggle directory\n",
    "# !mkdir -p ~/.kaggle\n",
    "\n",
    "# # Copy the kaggle.json file to kaggle directory\n",
    "# !cp kaggle.json ~/.kaggle\n",
    "\n",
    "# # Fix permissions\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!kaggle datasets download -d msambare/fer2013\n",
    "!unzip -o -q fer2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to caculate the number of each emotion classes\n",
    "train_dir = './train/'\n",
    "test_dir = './test/'\n",
    "\n",
    "def Classes_Count( path, name):\n",
    "    Classes_Dict = {}\n",
    "\n",
    "    for Class in os.listdir(path):\n",
    "\n",
    "        Full_Path = os.path.join(path, Class)\n",
    "        Classes_Dict[Class] = len(os.listdir(Full_Path))\n",
    "\n",
    "    df = pd.DataFrame(Classes_Dict, index=[name])\n",
    "\n",
    "    return df\n",
    "\n",
    "Train_Count = Classes_Count(train_dir, 'Train').transpose().sort_values(by=\"Train\", ascending=False)\n",
    "Test_Count = Classes_Count(test_dir, 'Test').transpose().sort_values(by=\"Test\", ascending=False)\n",
    "\n",
    "pd.concat([Train_Count,Test_Count] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize = (25, 8))\n",
    "image_count = 1\n",
    "BASE_URL = './train/'\n",
    "\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL +'/'+ directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(1, 7, image_count)\n",
    "                image_count += 1\n",
    "                image = cv2.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(directory, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "training_data = image_generator.flow_from_directory(train_dir,\n",
    "                                             target_size=(48,48),\n",
    "                                             batch_size=32,\n",
    "                                             color_mode = \"grayscale\",\n",
    "                                             class_mode = \"categorical\")\n",
    "\n",
    "test_data = image_generator.flow_from_directory(test_dir,\n",
    "                                          target_size=(48,48),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode='grayscale',\n",
    "                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "base_model = tf.keras.applications.EfficientNetB0(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation, GlobalAveragePooling2D, GaussianNoise\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(7,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n",
    "\n",
    "mcp = ModelCheckpoint('model.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)\n",
    "history=model.fit(training_data,validation_data=test_data,epochs = 50,verbose = 1,callbacks=[lrd,mcp,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    " \n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accu = model.evaluate(test_data)\n",
    "\n",
    "print(\"Loss on test set: \", loss)\n",
    "print(\"Accuracy on test set: \", accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fer_2013.h5')\n",
    "model.save_weights('fer_2013_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "test_labels = test_data.classes\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
