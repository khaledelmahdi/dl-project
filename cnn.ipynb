{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!pip install -q opencv-python\n",
    "!pip install -q pydot\n",
    "!pip install -q graphviz\n",
    "!pip install -q torchview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload kaggle.json file\n",
    "# from google.colab import files\n",
    "# files.upload()\n",
    "\n",
    "# Remove file if exist\n",
    "# !rm ~/.kaggle/kaggle.json\n",
    "\n",
    "# # Create a kaggle directory\n",
    "# !mkdir -p ~/.kaggle\n",
    "\n",
    "# # Copy the kaggle.json file to kaggle directory\n",
    "# !cp kaggle.json ~/.kaggle\n",
    "\n",
    "# # Fix permissions\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!kaggle datasets download -d msambare/fer2013\n",
    "!unzip -o fer2013.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define a function to caculate the number of each emotion classes\n",
    "train_dir = './train/'\n",
    "test_dir = './test/'\n",
    "\n",
    "def Classes_Count( path, name):\n",
    "    Classes_Dict = {}\n",
    "\n",
    "    for Class in os.listdir(path):\n",
    "\n",
    "        Full_Path = os.path.join(path, Class)\n",
    "        Classes_Dict[Class] = len(os.listdir(Full_Path))\n",
    "\n",
    "    df = pd.DataFrame(Classes_Dict, index=[name])\n",
    "\n",
    "    return df\n",
    "\n",
    "Train_Count = Classes_Count(train_dir, 'Train').transpose().sort_values(by=\"Train\", ascending=False)\n",
    "Test_Count = Classes_Count(test_dir, 'Test').transpose().sort_values(by=\"Test\", ascending=False)\n",
    "\n",
    "pd.concat([Train_Count,Test_Count] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize = (25, 8))\n",
    "image_count = 1\n",
    "BASE_URL = './train/'\n",
    "\n",
    "for directory in os.listdir(BASE_URL):\n",
    "    if directory[0] != '.':\n",
    "        for i, file in enumerate(os.listdir(BASE_URL +'/'+ directory)):\n",
    "            if i == 1:\n",
    "                break\n",
    "            else:\n",
    "                fig = plt.subplot(1, 7, image_count)\n",
    "                image_count += 1\n",
    "                image = cv2.imread(BASE_URL + directory + '/' + file)\n",
    "                plt.imshow(image)\n",
    "                plt.title(directory, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "training_data = image_generator.flow_from_directory(train_dir,\n",
    "                                             target_size=(48,48),\n",
    "                                             batch_size=32,\n",
    "                                             color_mode = \"grayscale\",\n",
    "                                             class_mode = \"categorical\")\n",
    "\n",
    "test_data = image_generator.flow_from_directory(test_dir,\n",
    "                                          target_size=(48,48),\n",
    "                                          batch_size=32,\n",
    "                                          color_mode='grayscale',\n",
    "                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer 1\n",
    "model.add(Conv2D(filters = 32, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(filters = 256, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Convolutional Layer 2\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Convolutional Layer 3\n",
    "model.add(Conv2D(filters = 128, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Convolutional Layer 4\n",
    "model.add(Conv2D(filters = 64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Flattening\n",
    "model.add(Flatten())\n",
    "## Full connection layer\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output Layer\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training the model\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=4, verbose=1)\n",
    "history = model.fit(training_data,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    validation_data = test_data,\n",
    "                    shuffle=True,\n",
    "                    callbacks = [early_stop]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "train_acc = history.history['accuracy']\n",
    "train_loss = history.history['loss']\n",
    "fig.set_size_inches(12, 4)\n",
    "\n",
    "ax[0].plot(history.history['accuracy'])\n",
    "ax[0].plot(history.history['val_accuracy'])\n",
    "ax[0].set_title('Training Accuracy vs Validation Accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'], loc='upper left')\n",
    " \n",
    "ax[1].plot(history.history['loss'])\n",
    "ax[1].plot(history.history['val_loss'])\n",
    "ax[1].set_title('Training Loss vs Validation Loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'], loc='upper left')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accu = model.evaluate(test_data)\n",
    "\n",
    "print(\"Loss on test set: \", loss)\n",
    "print(\"Accuracy on test set: \", accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fer_2013.h5')\n",
    "model.save_weights('fer_2013_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "test_labels = test_data.classes\n",
    "predictions = model.predict(test_data)\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "cm = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
